{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Imports for the HParams plugin\n",
    "from tensorboard.plugins.hparams import api_pb2\n",
    "from tensorboard.plugins.hparams import summary as hparams_summary\n",
    "from google.protobuf import struct_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "Network architect (from input to output):\n",
    "* Conv2D\n",
    "    * Number of kernels: 32\n",
    "    * Kernel size: hyperparamters\n",
    "* Conv2D\n",
    "    * Number of kernels: 64\n",
    "    * Kernel size: hyperparamters\n",
    "* Maxpooling\n",
    "    * Kernel size: (2, 2)\n",
    "* Dropout\n",
    "* Dense\n",
    "    * Number of units: hyperparameters\n",
    "* Dropout\n",
    "* Dense\n",
    "    * Number of units: 10\n",
    "\n",
    "With the overal architect being kept constant, the following hyperparameters are tuned:\n",
    "1. Learning rate\n",
    "2. Size of kernel used in Conv2D layers (2 Conv2D layers use kernels of the same size)\n",
    "3. Dropout rate\n",
    "4. Number of units on the first Dense layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameters lists\n",
    "learning_rate_list = [1e-3, 1e-2, 1e-1]\n",
    "kernel_size_list = [3, 5]\n",
    "dropout_rate_list = [0, 0.25, 0.5]\n",
    "dense_units_list = [32, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hyperparamters to Hparam \n",
    "def create_experiment_summary(learning_rate_list, dropout_rate_list, kernel_size_list, dense_units_list):\n",
    "    learning_rate_list_val = struct_pb2.ListValue()\n",
    "    learning_rate_list_val.extend(learning_rate_list)\n",
    "    \n",
    "    dropout_rate_list_val = struct_pb2.ListValue()\n",
    "    dropout_rate_list_val.extend(dropout_rate_list)\n",
    "    \n",
    "    kernel_size_list_val = struct_pb2.ListValue()\n",
    "    kernel_size_list_val.extend(kernel_size_list)\n",
    "    \n",
    "    dense_units_list_val = struct_pb2.ListValue()\n",
    "    dense_units_list_val.extend(dense_units_list)\n",
    "    \n",
    "    return hparams_summary.experiment_pb(\n",
    "      # The hyperparameters being changed\n",
    "      hparam_infos=[\n",
    "          api_pb2.HParamInfo(name='learning_rate',\n",
    "                             display_name='Learning Rate',\n",
    "                             type=api_pb2.DATA_TYPE_FLOAT64,\n",
    "                             domain_discrete=learning_rate_list_val),\n",
    "          api_pb2.HParamInfo(name='kernel_size',\n",
    "                             display_name='Kernel Size',\n",
    "                             type=api_pb2.DATA_TYPE_FLOAT64,\n",
    "                             domain_discrete=kernel_size_list_val),\n",
    "          api_pb2.HParamInfo(name='dropout_rate',\n",
    "                             display_name='Dropout rate',\n",
    "                             type=api_pb2.DATA_TYPE_FLOAT64,\n",
    "                             domain_discrete=dropout_rate_list_val),\n",
    "          api_pb2.HParamInfo(name='dense_units',\n",
    "                             display_name='Dense Units',\n",
    "                             type=api_pb2.DATA_TYPE_FLOAT64,\n",
    "                             domain_discrete=dense_units_list_val)\n",
    "      ],\n",
    "      # The metrics being tracked\n",
    "      metric_infos=[\n",
    "          api_pb2.MetricInfo(\n",
    "              name=api_pb2.MetricName(\n",
    "                  tag='accuracy'),\n",
    "              display_name='Accuracy'),\n",
    "      ]\n",
    "    )\n",
    "\n",
    "exp_summary = create_experiment_summary(learning_rate_list, dropout_rate_list, kernel_size_list, dense_units_list)\n",
    "root_logdir_writer = tf.summary.create_file_writer(\"logs_cnn/hparam_tuning\")\n",
    "with root_logdir_writer.as_default():\n",
    "    tf.summary.import_event(tf.compat.v1.Event(summary=exp_summary).SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model and adapt it to be trained with hyperparameters fed in form of dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(hparams):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=hparams['kernel_size'],\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "    \n",
    "    model.add(Conv2D(64, \n",
    "                     kernel_size=hparams['kernel_size'], \n",
    "                     activation='relu'))\n",
    "    \n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(hparams['dense_units'], activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(hparams['dropout_rate']))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    optim = tf.keras.optimizers.Adam(lr=hparams['learning_rate'])\n",
    "    \n",
    "    model.compile(optimizer=optim,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_images, \n",
    "              train_labels,\n",
    "              batch_size=64,\n",
    "              epochs=1) # Run with 1 epoch to speed things up for demo purposes\n",
    "    \n",
    "    _, accuracy = model.evaluate(test_images, test_labels)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each run, log an hparams summary with the hyperparameters and final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    writer = tf.summary.create_file_writer(run_dir)\n",
    "    summary_start = hparams_summary.session_start_pb(hparams=hparams)\n",
    "\n",
    "    with writer.as_default():\n",
    "        accuracy = train_cnn(hparams)\n",
    "        summary_end = hparams_summary.session_end_pb(api_pb2.STATUS_SUCCESS)\n",
    "\n",
    "        tf.summary.scalar('accuracy', accuracy, step=1, description=\"The accuracy\")\n",
    "        tf.summary.import_event(tf.compat.v1.Event(summary=summary_start).SerializeToString())\n",
    "        tf.summary.import_event(tf.compat.v1.Event(summary=summary_end).SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start trainning and log the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running training session 1\n",
      "{'learning_rate': 0.001, 'kernel_size': 3, 'dense_units': 32, 'dropout_rate': 0}\n",
      "60000/60000 [==============================] - 28s 469us/sample - loss: 0.1793 - accuracy: 0.9444\n",
      "10000/10000 [==============================] - 2s 177us/sample - loss: 0.0556 - accuracy: 0.9837\n",
      "--- Running training session 2\n",
      "{'learning_rate': 0.001, 'kernel_size': 3, 'dense_units': 32, 'dropout_rate': 0.25}\n",
      "60000/60000 [==============================] - 28s 467us/sample - loss: 0.2815 - accuracy: 0.9146\n",
      "10000/10000 [==============================] - 2s 171us/sample - loss: 0.0697 - accuracy: 0.9774\n",
      "--- Running training session 3\n",
      "{'learning_rate': 0.001, 'kernel_size': 3, 'dense_units': 32, 'dropout_rate': 0.5}\n",
      "60000/60000 [==============================] - 28s 461us/sample - loss: 0.4888 - accuracy: 0.8331\n",
      "10000/10000 [==============================] - 2s 172us/sample - loss: 0.0716 - accuracy: 0.9787\n",
      "--- Running training session 4\n",
      "{'learning_rate': 0.001, 'kernel_size': 3, 'dense_units': 128, 'dropout_rate': 0}\n",
      "60000/60000 [==============================] - 31s 516us/sample - loss: 0.1309 - accuracy: 0.9600\n",
      "10000/10000 [==============================] - 2s 177us/sample - loss: 0.0522 - accuracy: 0.9834\n",
      "--- Running training session 5\n",
      "{'learning_rate': 0.001, 'kernel_size': 3, 'dense_units': 128, 'dropout_rate': 0.25}\n",
      "60000/60000 [==============================] - 30s 499us/sample - loss: 0.1517 - accuracy: 0.9531\n",
      "10000/10000 [==============================] - 2s 180us/sample - loss: 0.0471 - accuracy: 0.9853\n",
      "--- Running training session 6\n",
      "{'learning_rate': 0.001, 'kernel_size': 3, 'dense_units': 128, 'dropout_rate': 0.5}\n",
      "60000/60000 [==============================] - 30s 496us/sample - loss: 0.2124 - accuracy: 0.9358\n",
      "10000/10000 [==============================] - 2s 180us/sample - loss: 0.0607 - accuracy: 0.9782\n",
      "--- Running training session 7\n",
      "{'learning_rate': 0.001, 'kernel_size': 5, 'dense_units': 32, 'dropout_rate': 0}\n",
      "60000/60000 [==============================] - 30s 493us/sample - loss: 0.1515 - accuracy: 0.9538\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.0495 - accuracy: 0.9842\n",
      "--- Running training session 8\n",
      "{'learning_rate': 0.001, 'kernel_size': 5, 'dense_units': 32, 'dropout_rate': 0.25}\n",
      "60000/60000 [==============================] - 29s 484us/sample - loss: 0.2257 - accuracy: 0.9305\n",
      "10000/10000 [==============================] - 2s 199us/sample - loss: 0.0464 - accuracy: 0.9855\n",
      "--- Running training session 9\n",
      "{'learning_rate': 0.001, 'kernel_size': 5, 'dense_units': 32, 'dropout_rate': 0.5}\n",
      "60000/60000 [==============================] - 29s 475us/sample - loss: 0.5229 - accuracy: 0.8250\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.0528 - accuracy: 0.9846\n",
      "--- Running training session 10\n",
      "{'learning_rate': 0.001, 'kernel_size': 5, 'dense_units': 128, 'dropout_rate': 0}\n",
      "60000/60000 [==============================] - 30s 505us/sample - loss: 0.1228 - accuracy: 0.9622\n",
      "10000/10000 [==============================] - 2s 205us/sample - loss: 0.0390 - accuracy: 0.9884\n",
      "--- Running training session 11\n",
      "{'learning_rate': 0.001, 'kernel_size': 5, 'dense_units': 128, 'dropout_rate': 0.25}\n",
      "60000/60000 [==============================] - 30s 501us/sample - loss: 0.1429 - accuracy: 0.9566\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.0387 - accuracy: 0.9867\n",
      "--- Running training session 12\n",
      "{'learning_rate': 0.001, 'kernel_size': 5, 'dense_units': 128, 'dropout_rate': 0.5}\n",
      "60000/60000 [==============================] - 30s 501us/sample - loss: 0.1861 - accuracy: 0.9440\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.0465 - accuracy: 0.9847\n",
      "--- Running training session 13\n",
      "{'learning_rate': 0.01, 'kernel_size': 3, 'dense_units': 32, 'dropout_rate': 0}\n",
      "60000/60000 [==============================] - 27s 448us/sample - loss: 0.1413 - accuracy: 0.9564\n",
      "10000/10000 [==============================] - 2s 183us/sample - loss: 0.0615 - accuracy: 0.9796\n",
      "--- Running training session 14\n",
      "{'learning_rate': 0.01, 'kernel_size': 3, 'dense_units': 32, 'dropout_rate': 0.25}\n",
      "60000/60000 [==============================] - 28s 460us/sample - loss: 0.2562 - accuracy: 0.9220\n",
      "10000/10000 [==============================] - 2s 168us/sample - loss: 0.0885 - accuracy: 0.9708\n",
      "--- Running training session 15\n",
      "{'learning_rate': 0.01, 'kernel_size': 3, 'dense_units': 32, 'dropout_rate': 0.5}\n",
      "60000/60000 [==============================] - 27s 449us/sample - loss: 0.4509 - accuracy: 0.8441\n",
      "10000/10000 [==============================] - 2s 178us/sample - loss: 0.0831 - accuracy: 0.9762\n",
      "--- Running training session 16\n",
      "{'learning_rate': 0.01, 'kernel_size': 3, 'dense_units': 128, 'dropout_rate': 0}\n",
      "60000/60000 [==============================] - 28s 474us/sample - loss: 0.1693 - accuracy: 0.9488\n",
      "10000/10000 [==============================] - 2s 182us/sample - loss: 0.0672 - accuracy: 0.9783\n",
      "--- Running training session 17\n",
      "{'learning_rate': 0.01, 'kernel_size': 3, 'dense_units': 128, 'dropout_rate': 0.25}\n",
      "60000/60000 [==============================] - 29s 489us/sample - loss: 0.1851 - accuracy: 0.9443\n",
      "10000/10000 [==============================] - 2s 174us/sample - loss: 0.0505 - accuracy: 0.9832\n",
      "--- Running training session 18\n",
      "{'learning_rate': 0.01, 'kernel_size': 3, 'dense_units': 128, 'dropout_rate': 0.5}\n",
      "60000/60000 [==============================] - 29s 484us/sample - loss: 0.2843 - accuracy: 0.9142\n",
      "10000/10000 [==============================] - 2s 179us/sample - loss: 0.0619 - accuracy: 0.9803\n",
      "--- Running training session 19\n",
      "{'learning_rate': 0.01, 'kernel_size': 5, 'dense_units': 32, 'dropout_rate': 0}\n",
      "60000/60000 [==============================] - 28s 472us/sample - loss: 0.1848 - accuracy: 0.9423\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.0934 - accuracy: 0.9711\n",
      "--- Running training session 20\n",
      "{'learning_rate': 0.01, 'kernel_size': 5, 'dense_units': 32, 'dropout_rate': 0.25}\n",
      "60000/60000 [==============================] - 28s 463us/sample - loss: 0.3362 - accuracy: 0.8914\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.0776 - accuracy: 0.9766\n",
      "--- Running training session 21\n",
      "{'learning_rate': 0.01, 'kernel_size': 5, 'dense_units': 32, 'dropout_rate': 0.5}\n",
      "60000/60000 [==============================] - 28s 464us/sample - loss: 2.3061 - accuracy: 0.1100\n",
      "10000/10000 [==============================] - 2s 210us/sample - loss: 2.3025 - accuracy: 0.1135\n",
      "--- Running training session 22\n",
      "{'learning_rate': 0.01, 'kernel_size': 5, 'dense_units': 128, 'dropout_rate': 0}\n",
      "60000/60000 [==============================] - 30s 501us/sample - loss: 0.2024 - accuracy: 0.9402\n",
      "10000/10000 [==============================] - 2s 206us/sample - loss: 0.0821 - accuracy: 0.9736\n",
      "--- Running training session 23\n",
      "{'learning_rate': 0.01, 'kernel_size': 5, 'dense_units': 128, 'dropout_rate': 0.25}\n",
      "60000/60000 [==============================] - 30s 495us/sample - loss: 0.2012 - accuracy: 0.9398\n",
      "10000/10000 [==============================] - 2s 211us/sample - loss: 0.0574 - accuracy: 0.9817\n",
      "--- Running training session 24\n",
      "{'learning_rate': 0.01, 'kernel_size': 5, 'dense_units': 128, 'dropout_rate': 0.5}\n",
      "60000/60000 [==============================] - 30s 496us/sample - loss: 0.2409 - accuracy: 0.9294\n",
      "10000/10000 [==============================] - 2s 213us/sample - loss: 0.0880 - accuracy: 0.9730\n",
      "--- Running training session 25\n",
      "{'learning_rate': 0.1, 'kernel_size': 3, 'dense_units': 32, 'dropout_rate': 0}\n",
      "60000/60000 [==============================] - 26s 440us/sample - loss: 2.6973 - accuracy: 0.1028\n",
      "10000/10000 [==============================] - 2s 183us/sample - loss: 2.3126 - accuracy: 0.0958\n",
      "--- Running training session 26\n",
      "{'learning_rate': 0.1, 'kernel_size': 3, 'dense_units': 32, 'dropout_rate': 0.25}\n",
      "60000/60000 [==============================] - 27s 444us/sample - loss: 1.3491 - accuracy: 0.7139\n",
      "10000/10000 [==============================] - 2s 184us/sample - loss: 0.4585 - accuracy: 0.8692\n",
      "--- Running training session 27\n",
      "{'learning_rate': 0.1, 'kernel_size': 3, 'dense_units': 32, 'dropout_rate': 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 31s 517us/sample - loss: 2.9139 - accuracy: 0.1027\n",
      "10000/10000 [==============================] - 2s 173us/sample - loss: 2.3099 - accuracy: 0.0958\n",
      "--- Running training session 28\n",
      "{'learning_rate': 0.1, 'kernel_size': 3, 'dense_units': 128, 'dropout_rate': 0}\n",
      "60000/60000 [==============================] - 33s 542us/sample - loss: 1.8031 - accuracy: 0.8189\n",
      "10000/10000 [==============================] - 2s 188us/sample - loss: 0.3060 - accuracy: 0.9056\n",
      "--- Running training session 29\n",
      "{'learning_rate': 0.1, 'kernel_size': 3, 'dense_units': 128, 'dropout_rate': 0.25}\n",
      "60000/60000 [==============================] - 33s 545us/sample - loss: 3.8444 - accuracy: 0.1023\n",
      "10000/10000 [==============================] - 2s 175us/sample - loss: 2.3098 - accuracy: 0.1010\n",
      "--- Running training session 30\n",
      "{'learning_rate': 0.1, 'kernel_size': 3, 'dense_units': 128, 'dropout_rate': 0.5}\n",
      "60000/60000 [==============================] - 32s 534us/sample - loss: 3.4238 - accuracy: 0.1050\n",
      "10000/10000 [==============================] - 2s 172us/sample - loss: 2.3045 - accuracy: 0.1032\n",
      "--- Running training session 31\n",
      "{'learning_rate': 0.1, 'kernel_size': 5, 'dense_units': 32, 'dropout_rate': 0}\n",
      "60000/60000 [==============================] - 32s 527us/sample - loss: 4.8735 - accuracy: 0.1039\n",
      "10000/10000 [==============================] - 2s 196us/sample - loss: 2.3093 - accuracy: 0.1010\n",
      "--- Running training session 32\n",
      "{'learning_rate': 0.1, 'kernel_size': 5, 'dense_units': 32, 'dropout_rate': 0.25}\n",
      "60000/60000 [==============================] - 31s 510us/sample - loss: 4.2605 - accuracy: 0.1042\n",
      "10000/10000 [==============================] - 2s 197us/sample - loss: 2.3125 - accuracy: 0.0982\n",
      "--- Running training session 33\n",
      "{'learning_rate': 0.1, 'kernel_size': 5, 'dense_units': 32, 'dropout_rate': 0.5}\n",
      "60000/60000 [==============================] - 30s 507us/sample - loss: 5.1500 - accuracy: 0.1031\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 2.3062 - accuracy: 0.0958\n",
      "--- Running training session 34\n",
      "{'learning_rate': 0.1, 'kernel_size': 5, 'dense_units': 128, 'dropout_rate': 0}\n",
      "60000/60000 [==============================] - 33s 552us/sample - loss: 6.6776 - accuracy: 0.1042\n",
      "10000/10000 [==============================] - 2s 238us/sample - loss: 2.3081 - accuracy: 0.1135\n",
      "--- Running training session 35\n",
      "{'learning_rate': 0.1, 'kernel_size': 5, 'dense_units': 128, 'dropout_rate': 0.25}\n",
      "60000/60000 [==============================] - 31s 513us/sample - loss: 5.5402 - accuracy: 0.6873\n",
      "10000/10000 [==============================] - 2s 182us/sample - loss: 0.5052 - accuracy: 0.8372\n",
      "--- Running training session 36\n",
      "{'learning_rate': 0.1, 'kernel_size': 5, 'dense_units': 128, 'dropout_rate': 0.5}\n",
      "60000/60000 [==============================] - 31s 509us/sample - loss: 6.8367 - accuracy: 0.1060\n",
      "10000/10000 [==============================] - 21s 2ms/sample - loss: 2.3113 - accuracy: 0.0958\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for learning_rate in learning_rate_list:\n",
    "    for kernel_size in kernel_size_list:\n",
    "        for dense_units in dense_units_list:\n",
    "            for dropout_rate in dropout_rate_list:\n",
    "                hparams = {'learning_rate':learning_rate,\n",
    "                           'kernel_size': kernel_size,\n",
    "                           'dense_units': dense_units,\n",
    "                           'dropout_rate': dropout_rate\n",
    "                          }\n",
    "                print('--- Running training session %d' % (session_num + 1))\n",
    "                print(hparams)\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                run(\"logs/hparam_tuning/\" + run_name, hparams)\n",
    "                session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "# test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# # Normalize pixel values to be between 0 and 1\n",
    "# train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 16s 272us/sample - loss: 0.1445 - accuracy: 0.9549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f859c3d81d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(train_images, train_labels, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
