{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Imports for the HParams plugin\n",
    "from tensorboard.plugins.hparams import api_pb2\n",
    "from tensorboard.plugins.hparams import summary as hparams_summary\n",
    "from google.protobuf import struct_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "Network architect (from input to output):\n",
    "* Conv2D\n",
    "    * Number of kernels: 32\n",
    "    * Kernel size: hyperparamters\n",
    "* Conv2D\n",
    "    * Number of kernels: 64\n",
    "    * Kernel size: hyperparamters\n",
    "* Maxpooling\n",
    "    * Kernel size: (2, 2)\n",
    "* Dropout\n",
    "* Dense\n",
    "    * Number of units: hyperparameters\n",
    "* Dropout\n",
    "* Dense\n",
    "    * Number of units: 10\n",
    "\n",
    "With the overal architect being kept constant, the following hyperparameters are tuned:\n",
    "1. Learning rate\n",
    "2. Size of kernel used in Conv2D layers (2 Conv2D layers use kernels of the same size)\n",
    "3. Dropout rate\n",
    "4. Number of units on the first Dense layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameters lists\n",
    "learning_rate_list = [1e-3, 1e-2, 1e-1]\n",
    "kernel_size_list = [3, 5]\n",
    "dropout_rate_list = [0., 0.25, 0.5]\n",
    "dense_units_list = [32, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hyperparamters to Hparam \n",
    "def create_experiment_summary(learning_rate_list, dropout_rate_list, kernel_size_list, dense_units_list):\n",
    "    learning_rate_list_val = struct_pb2.ListValue()\n",
    "    learning_rate_list_val.extend(learning_rate_list)\n",
    "    \n",
    "    dropout_rate_list_val = struct_pb2.ListValue()\n",
    "    dropout_rate_list_val.extend(dropout_rate_list)\n",
    "    \n",
    "    kernel_size_list_val = struct_pb2.ListValue()\n",
    "    kernel_size_list_val.extend(kernel_size_list)\n",
    "    \n",
    "    dense_units_list_val = struct_pb2.ListValue()\n",
    "    dense_units_list_val.extend(dense_units_list)\n",
    "    \n",
    "    return hparams_summary.experiment_pb(\n",
    "      # The hyperparameters being changed\n",
    "      hparam_infos=[\n",
    "          api_pb2.HParamInfo(name='learning_rate',\n",
    "                             display_name='Learning Rate',\n",
    "                             type=api_pb2.DATA_TYPE_FLOAT64,\n",
    "                             domain_discrete=learning_rate_list_val),\n",
    "          api_pb2.HParamInfo(name='kernel_size',\n",
    "                             display_name='Kernel Size',\n",
    "                             type=api_pb2.DATA_TYPE_FLOAT64,\n",
    "                             domain_discrete=kernel_size_list_val),\n",
    "          api_pb2.HParamInfo(name='dropout_rate',\n",
    "                             display_name='Dropout rate',\n",
    "                             type=api_pb2.DATA_TYPE_FLOAT64,\n",
    "                             domain_discrete=dropout_rate_list_val),\n",
    "          api_pb2.HParamInfo(name='dense_units',\n",
    "                             display_name='Dense Units',\n",
    "                             type=api_pb2.DATA_TYPE_FLOAT64,\n",
    "                             domain_discrete=dense_units_list_val)\n",
    "      ],\n",
    "      # The metrics being tracked\n",
    "      metric_infos=[\n",
    "          api_pb2.MetricInfo(\n",
    "              name=api_pb2.MetricName(\n",
    "                  tag='accuracy'),\n",
    "              display_name='Accuracy'),\n",
    "      ]\n",
    "    )\n",
    "\n",
    "exp_summary = create_experiment_summary(learning_rate_list, dropout_rate_list, kernel_size_list, dense_units_list)\n",
    "root_logdir_writer = tf.summary.create_file_writer(\"logs_cnn/hparam_tuning\")\n",
    "with root_logdir_writer.as_default():\n",
    "    tf.summary.import_event(tf.compat.v1.Event(summary=exp_summary).SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model and adapt it to be trained with hyperparameters fed in form of dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(hparams):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=hparams['kernel_size'],\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "    \n",
    "    model.add(Conv2D(64, \n",
    "                     kernel_size=hparams['kernel_size'], \n",
    "                     activation='relu'))\n",
    "    \n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(hparams['dense_units'], activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(hparams['dropout_rate']))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    optim = tf.keras.optimizers.Adam(lr=hparams['learning_rate'])\n",
    "    \n",
    "    model.compile(optimizer=optim,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_images, \n",
    "              train_labels,\n",
    "              batch_size=64,\n",
    "              epochs=1) # Run with 1 epoch to speed things up for demo purposes\n",
    "    \n",
    "    _, accuracy = model.evaluate(test_images, test_labels)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each run, log an hparams summary with the hyperparameters and final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    writer = tf.summary.create_file_writer(run_dir)\n",
    "    summary_start = hparams_summary.session_start_pb(hparams=hparams)\n",
    "\n",
    "    with writer.as_default():\n",
    "        accuracy = train_cnn(hparams)\n",
    "        summary_end = hparams_summary.session_end_pb(api_pb2.STATUS_SUCCESS)\n",
    "\n",
    "        tf.summary.scalar('accuracy', accuracy, step=1, description=\"The accuracy\")\n",
    "        tf.summary.import_event(tf.compat.v1.Event(summary=summary_start).SerializeToString())\n",
    "        tf.summary.import_event(tf.compat.v1.Event(summary=summary_end).SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start trainning and log the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running training session 1\n",
      "{'learning_rate': 0.001, 'kernel_size': 3, 'dropout_rate': 0, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 31s 521us/sample - loss: 0.1643 - accuracy: 0.9497\n",
      "10000/10000 [==============================] - 2s 191us/sample - loss: 0.0516 - accuracy: 0.9843\n",
      "--- Running training session 2\n",
      "{'learning_rate': 0.001, 'kernel_size': 3, 'dropout_rate': 0.25, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 32s 530us/sample - loss: 0.3124 - accuracy: 0.9029\n",
      "10000/10000 [==============================] - 2s 170us/sample - loss: 0.0633 - accuracy: 0.9808\n",
      "--- Running training session 3\n",
      "{'learning_rate': 0.001, 'kernel_size': 3, 'dropout_rate': 0.5, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 28s 463us/sample - loss: 0.5177 - accuracy: 0.8218\n",
      "10000/10000 [==============================] - 2s 172us/sample - loss: 0.0798 - accuracy: 0.9756\n",
      "--- Running training session 4\n",
      "{'learning_rate': 0.001, 'kernel_size': 3, 'dropout_rate': 0, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 35s 590us/sample - loss: 0.1351 - accuracy: 0.9588\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.0403 - accuracy: 0.9867\n",
      "--- Running training session 5\n",
      "{'learning_rate': 0.001, 'kernel_size': 3, 'dropout_rate': 0.25, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 30s 498us/sample - loss: 0.1551 - accuracy: 0.9521\n",
      "10000/10000 [==============================] - 2s 181us/sample - loss: 0.0428 - accuracy: 0.9866\n",
      "--- Running training session 6\n",
      "{'learning_rate': 0.001, 'kernel_size': 3, 'dropout_rate': 0.5, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 30s 501us/sample - loss: 0.2025 - accuracy: 0.9386\n",
      "10000/10000 [==============================] - 2s 179us/sample - loss: 0.0474 - accuracy: 0.9854\n",
      "--- Running training session 7\n",
      "{'learning_rate': 0.001, 'kernel_size': 5, 'dropout_rate': 0, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 30s 500us/sample - loss: 0.1616 - accuracy: 0.9507\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.0679 - accuracy: 0.9770\n",
      "--- Running training session 8\n",
      "{'learning_rate': 0.001, 'kernel_size': 5, 'dropout_rate': 0.25, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 29s 479us/sample - loss: 0.2983 - accuracy: 0.9068\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.0517 - accuracy: 0.9837\n",
      "--- Running training session 9\n",
      "{'learning_rate': 0.001, 'kernel_size': 5, 'dropout_rate': 0.5, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 29s 485us/sample - loss: 0.5102 - accuracy: 0.8247\n",
      "10000/10000 [==============================] - 2s 206us/sample - loss: 0.0655 - accuracy: 0.9796\n",
      "--- Running training session 10\n",
      "{'learning_rate': 0.001, 'kernel_size': 5, 'dropout_rate': 0, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 30s 506us/sample - loss: 0.1187 - accuracy: 0.9633\n",
      "10000/10000 [==============================] - 2s 206us/sample - loss: 0.0364 - accuracy: 0.9874\n",
      "--- Running training session 11\n",
      "{'learning_rate': 0.001, 'kernel_size': 5, 'dropout_rate': 0.25, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 30s 506us/sample - loss: 0.1436 - accuracy: 0.9560\n",
      "10000/10000 [==============================] - 2s 208us/sample - loss: 0.0370 - accuracy: 0.9862\n",
      "--- Running training session 12\n",
      "{'learning_rate': 0.001, 'kernel_size': 5, 'dropout_rate': 0.5, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 31s 517us/sample - loss: 0.1781 - accuracy: 0.9463\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.0435 - accuracy: 0.9857\n",
      "--- Running training session 13\n",
      "{'learning_rate': 0.01, 'kernel_size': 3, 'dropout_rate': 0, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 27s 450us/sample - loss: 0.1595 - accuracy: 0.9502\n",
      "10000/10000 [==============================] - 2s 178us/sample - loss: 0.0647 - accuracy: 0.9793\n",
      "--- Running training session 14\n",
      "{'learning_rate': 0.01, 'kernel_size': 3, 'dropout_rate': 0.25, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 27s 442us/sample - loss: 0.2861 - accuracy: 0.9104\n",
      "10000/10000 [==============================] - 2s 179us/sample - loss: 0.0702 - accuracy: 0.9787\n",
      "--- Running training session 15\n",
      "{'learning_rate': 0.01, 'kernel_size': 3, 'dropout_rate': 0.5, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 27s 447us/sample - loss: 0.4117 - accuracy: 0.8630\n",
      "10000/10000 [==============================] - 2s 184us/sample - loss: 0.0898 - accuracy: 0.9718\n",
      "--- Running training session 16\n",
      "{'learning_rate': 0.01, 'kernel_size': 3, 'dropout_rate': 0, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 29s 486us/sample - loss: 0.1559 - accuracy: 0.9532\n",
      "10000/10000 [==============================] - 2s 186us/sample - loss: 0.0989 - accuracy: 0.9700\n",
      "--- Running training session 17\n",
      "{'learning_rate': 0.01, 'kernel_size': 3, 'dropout_rate': 0.25, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 29s 483us/sample - loss: 0.1939 - accuracy: 0.9427\n",
      "10000/10000 [==============================] - 2s 185us/sample - loss: 0.0821 - accuracy: 0.9765\n",
      "--- Running training session 18\n",
      "{'learning_rate': 0.01, 'kernel_size': 3, 'dropout_rate': 0.5, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 29s 484us/sample - loss: 0.4856 - accuracy: 0.8417\n",
      "10000/10000 [==============================] - 2s 185us/sample - loss: 0.1233 - accuracy: 0.9618\n",
      "--- Running training session 19\n",
      "{'learning_rate': 0.01, 'kernel_size': 5, 'dropout_rate': 0, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 28s 467us/sample - loss: 0.1982 - accuracy: 0.9384\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.0906 - accuracy: 0.9716\n",
      "--- Running training session 20\n",
      "{'learning_rate': 0.01, 'kernel_size': 5, 'dropout_rate': 0.25, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 28s 468us/sample - loss: 0.4218 - accuracy: 0.8633\n",
      "10000/10000 [==============================] - 2s 209us/sample - loss: 0.0840 - accuracy: 0.9749\n",
      "--- Running training session 21\n",
      "{'learning_rate': 0.01, 'kernel_size': 5, 'dropout_rate': 0.5, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 28s 471us/sample - loss: 0.7408 - accuracy: 0.7545\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.1744 - accuracy: 0.9467\n",
      "--- Running training session 22\n",
      "{'learning_rate': 0.01, 'kernel_size': 5, 'dropout_rate': 0, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 30s 501us/sample - loss: 0.1836 - accuracy: 0.9465\n",
      "10000/10000 [==============================] - 2s 210us/sample - loss: 0.0662 - accuracy: 0.9778\n",
      "--- Running training session 23\n",
      "{'learning_rate': 0.01, 'kernel_size': 5, 'dropout_rate': 0.25, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 30s 501us/sample - loss: 0.2130 - accuracy: 0.9366\n",
      "10000/10000 [==============================] - 2s 210us/sample - loss: 0.0723 - accuracy: 0.9793\n",
      "--- Running training session 24\n",
      "{'learning_rate': 0.01, 'kernel_size': 5, 'dropout_rate': 0.5, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 30s 500us/sample - loss: 0.3800 - accuracy: 0.8808\n",
      "10000/10000 [==============================] - 2s 207us/sample - loss: 0.0812 - accuracy: 0.9731\n",
      "--- Running training session 25\n",
      "{'learning_rate': 0.1, 'kernel_size': 3, 'dropout_rate': 0, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 27s 442us/sample - loss: 2.5766 - accuracy: 0.1063\n",
      "10000/10000 [==============================] - 2s 176us/sample - loss: 2.3140 - accuracy: 0.0980\n",
      "--- Running training session 26\n",
      "{'learning_rate': 0.1, 'kernel_size': 3, 'dropout_rate': 0.25, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 26s 435us/sample - loss: 2.6510 - accuracy: 0.1040\n",
      "10000/10000 [==============================] - 2s 175us/sample - loss: 2.3091 - accuracy: 0.1135\n",
      "--- Running training session 27\n",
      "{'learning_rate': 0.1, 'kernel_size': 3, 'dropout_rate': 0.5, 'dense_units': 32}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 29s 487us/sample - loss: 3.3390 - accuracy: 0.1037\n",
      "10000/10000 [==============================] - 2s 174us/sample - loss: 2.3047 - accuracy: 0.1135\n",
      "--- Running training session 28\n",
      "{'learning_rate': 0.1, 'kernel_size': 3, 'dropout_rate': 0, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 31s 522us/sample - loss: 4.1595 - accuracy: 0.1048\n",
      "10000/10000 [==============================] - 2s 178us/sample - loss: 2.3045 - accuracy: 0.1028\n",
      "--- Running training session 29\n",
      "{'learning_rate': 0.1, 'kernel_size': 3, 'dropout_rate': 0.25, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 31s 510us/sample - loss: 3.9612 - accuracy: 0.1033\n",
      "10000/10000 [==============================] - 2s 176us/sample - loss: 2.3128 - accuracy: 0.1028\n",
      "--- Running training session 30\n",
      "{'learning_rate': 0.1, 'kernel_size': 3, 'dropout_rate': 0.5, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 31s 510us/sample - loss: 3.6096 - accuracy: 0.1037\n",
      "10000/10000 [==============================] - 2s 177us/sample - loss: 2.3089 - accuracy: 0.0982\n",
      "--- Running training session 31\n",
      "{'learning_rate': 0.1, 'kernel_size': 5, 'dropout_rate': 0, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 29s 491us/sample - loss: 3.3762 - accuracy: 0.1058\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 2.3110 - accuracy: 0.1135\n",
      "--- Running training session 32\n",
      "{'learning_rate': 0.1, 'kernel_size': 5, 'dropout_rate': 0.25, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 29s 488us/sample - loss: 4.7986 - accuracy: 0.1048\n",
      "10000/10000 [==============================] - 2s 198us/sample - loss: 2.3156 - accuracy: 0.1009\n",
      "--- Running training session 33\n",
      "{'learning_rate': 0.1, 'kernel_size': 5, 'dropout_rate': 0.5, 'dense_units': 32}\n",
      "60000/60000 [==============================] - 30s 495us/sample - loss: 5.6608 - accuracy: 0.1026\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 2.3041 - accuracy: 0.1032\n",
      "--- Running training session 34\n",
      "{'learning_rate': 0.1, 'kernel_size': 5, 'dropout_rate': 0, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 31s 509us/sample - loss: 11.8803 - accuracy: 0.1030\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 2.3057 - accuracy: 0.1028\n",
      "--- Running training session 35\n",
      "{'learning_rate': 0.1, 'kernel_size': 5, 'dropout_rate': 0.25, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 30s 508us/sample - loss: 8.4387 - accuracy: 0.1040\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 2.3124 - accuracy: 0.1028\n",
      "--- Running training session 36\n",
      "{'learning_rate': 0.1, 'kernel_size': 5, 'dropout_rate': 0.5, 'dense_units': 128}\n",
      "60000/60000 [==============================] - 30s 507us/sample - loss: 6.6959 - accuracy: 0.1025\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 2.3065 - accuracy: 0.1135\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for learning_rate in learning_rate_list:\n",
    "    for kernel_size in kernel_size_list:\n",
    "        for dense_units in dense_units_list:\n",
    "            for dropout_rate in dropout_rate_list:\n",
    "                hparams = {'learning_rate':learning_rate,\n",
    "                           'kernel_size': kernel_size,\n",
    "                           'dropout_rate': dropout_rate,\n",
    "                           'dense_units': dense_units\n",
    "                          }\n",
    "                print('--- Running training session %d' % (session_num + 1))\n",
    "                print(hparams)\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                run(\"logs_cnn/hparam_tuning/\" + run_name, hparams)\n",
    "                session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "# test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# # Normalize pixel values to be between 0 and 1\n",
    "# train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 16s 272us/sample - loss: 0.1445 - accuracy: 0.9549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f859c3d81d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(train_images, train_labels, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
